# AWS Lambda with Python to Automate Writing any data to a DynamoDB Table from S3---

1) Create IAM Role-
role-aws service-lambda-next-search and select dynamodb full access- create role
2) create lambda function-select python run time (python version) -select existing role- create function
3) code-remove existing code-copy and paste our code and save it (do not click on deploy)
3) go to s3 and create bucket
4) open lambda and add trigger(s3 bucket)
5) go to dynamodb and create table( table and uniwue id shoud be same that is mentioned on the function code) 
6) open lambda and deploy code
7) go to s3 and upload any type of object or data
8) output- object will show into the table item

# we can run below python code into python version 3.7,3.8,3.9,3.10,3.11
import boto3
from uuid import uuid4
def lambda_handler(event, context):
    s3 = boto3.client("s3")
    dynamodb = boto3.resource('dynamodb')
    for record in event['Records']:
        bucket_name = record['s3']['bucket']['name']
        object_key = record['s3']['object']['key']
        size = record['s3']['object'].get('size', -1)
        event_name = record ['eventName']
        event_time = record['eventTime']
        dynamoTable = dynamodb.Table('newtable')
        dynamoTable.put_item(
            Item={'unique': str(uuid4()), 'Bucket': bucket_name, 'Object': object_key,'Size': size, 'Event': event_name, 'EventTime': event_time})











