Here are five cost optimization ways that we can apply to optimize cost:
1) Right size – the resources you provision must match your requirements and needs. For example, you should provision CPU, storage, network throughput, and memory for computing.
2) Increase elasticity (ASG)
3) Leverage the right pricing model – AWS offers various pricing models, including on-demand pricing, Spot Instances, and Reserved Instances. The pricing model you choose should allow you to optimize costs according to your workload’s needs. For example, reserved instances are ideal for predictable workloads.
4) Optimize storage – AWS offers several storage tiers, each providing different performance at different costs. You can optimize storage and maintain the required performance and availability by identifying the appropriate destination for specific data types. For example, for lower performance requirements, you can use Amazon EBS Throughput Optimized HDD (st1), which costs less than General Purpose SSD (gp2).
5) Measure & monitor AWS service and resource – since cloud environments are dynamic, you need to establish measurements and monitor for accurate visibility and continuous costs optimization. You should define metrics, set specific targets, and review the information regularly.

# AWS Cost Optimization Tools
Here are several AWS cost optimization tools available free from Amazon:
1) AWS Cost Explorer-
2) AWS Budgets-
AWS Budgets can help you set and enforce budgets for each AWS service. When budgets are exceeded or reached, you can receive messages or emails from the Simple Notification Service (SNS). You can define an overall cost budget or connect a budget to certain data points, including data usage or the number of instances. The tool provides dashboard views similar to those generated by the Cost Explorer, displaying how each service is used compared to its budget.
3) AWS Pricing Calculator
AWS Pricing Calculator enables you to estimate the cost of use cases on AWS. It lets you generate monthly cost estimates for all regions supported by a certain service. You can model a solution before building it, explore the pricing points and calculations of your estimate, as well as find available instance types and contract terms that meet your requirements. This can help you make informed decisions, plan your AWS cost and usage, as well as estimate the costs of setting up a new set of instances and services.
# AWS Cost Optimization Best Practices-
1. Choose the Appropriate AWS Region
2. Create Schedules to Turn Off Unused Instances -
@ Shut down unused instances at the end of a working day or during weekends and vacations.
@ When optimizing non-production instances, you should prepare on and off hours in advance.
@ Evaluate usage metrics and then decide when instances are frequently used. You can then implement more accurate schedules. Alternatively, you can apply an always-stopped schedule, which you can disrupt when providing access to these instances.
@ Determine whether you are paying for EBS quantities as well as other relevant elements while your instances are not in use.
3. Identifying Under-Utilized Amazon EC2 Instances -
The AWS Cost Explorer helps you visualize and manage the cost of Amazon services. The tool provides a Resource Optimization report, which shows idle or under-utilized EC2 instances. You can lower your costs by stopping or scaling down these instances.
Here are three tools to help you to stop wasting money on low utilization EC2 instances:
AWS Instance Scheduler – a pre-integrated Amazon solution you can use to stop instances automatically on a predetermined schedule, for example outside business hours.
AWS Operations Conductor – automatically resizes EC2 instances based on recommendations provided by Cost Explorer.
AWS Compute Optimizer – provides recommendations about the most appropriate instance type for each workload. This goes beyond scaling down within a group of instances. It offers recommendations for downsizing instances across groups, as well as recommendations for upsizing to eliminate performance bottlenecks, and recommendations for EC2 instances in an Auto Scaling group.
4. Reducing EC2 Costs with EC2 Spot Instances -
5. Optimizing EC2 Auto Scaling Groups (ASG) Configuration
ASGs can take advantage of Amazon EC2 Auto Scaling features, such as health checks and custom scaling policies based on application metrics or preset schedules. You can dynamically add or remove EC2 instances from an ASG based on predetermined rules or dynamically, in response to application loads.
When scaling up—try to add instances less aggressively, monitoring to see that application performance is not affected
When scaling down—try to reduce instances to the minimum necessary to maintain current application loads
6. Use Reserved Instances
Service support—you can now use RIs for EC2, RDS, Redshift, ElastiCache and DynamoDB.
7. Leveraging Compute Savings Plans to Reduce Compute Costs
8. Monitor the Use of Storage and Delete Unused EBS Volumes
9. Identifying and Deleting unused Snapshots-
When you terminate an EC2 instance, the associated EBS volume is also deleted by default. However, it’s easy to forget that snapshots you created as backups of those EBS volumes are still in S3, and you’re still paying an ongoing monthly fee to store them.
It is best to set up automated lifecycle management of EBS snapshots, via Amazon Data Lifecycle Manager, to ensure that you do not maintain snapshots for longer than needed.
10. Deleting Idle Load Balancers and Optimizing Bandwidth Use
Check your Elastic Load Balancing configuration to see which load balancers are not currently used. Every load balancer incurs ongoing costs. If your load balancer doesn’t have any backend instances associated with it, or network traffic is very low, it is not being used effectively and is wasting resources.
You can use AWS Trusted Advisor to identify load balancers with a low number of requests (a good rule of thumb is less than 100 requests in the last 7 days). Reduce costs by removing idle load balancers—you can track overall data transfer costs with Cost Explorer.
11) Analyze Amazon S3 usage and reduce cost by leveraging lower cost storage tiers
Use S3 Analytics to analyze storage access patterns on the object data set for 30 days or longer. It makes recommendations on where you can leverage S3 Infrequently Accessed (S3 IA) to reduce costs. You can automate moving these objects into lower cost storage tier using Life Cycle Policies. Alternately, you can also use S3 Intelligent-Tiering, which automatically analyzes and moves your objects to the appropriate storage tier.
12. Identify Amazon RDS, Amazon Redshift instances with low utilization and reduce cost by stopping (RDS) and pausing (Redshift)
Use the Trusted Advisor Amazon RDS Idle DB instances check, to identify DB instances which have not had any connection over the last 7 days. To reduce costs, stop these DB instances using the automation steps described in thisblog post. For Redshift, use the Trusted Advisor Underutilized Redshift clusters check, to identify clusters which have had no connections for the last 7 days, and less than 5% cluster wide average CPU utilization for 99% of the last 7 days.
5 Analyze Amazon DynamoDB usage and reduce cost by leveraging Autoscaling or On-demand
Analyze your DynamoDB usage by monitoring 2 metrics, ConsumedReadCapacityUnits and ConsumedWriteCapacityUnits, in CloudWatch. To automatically scale (in and out) your DynamoDB table, use the AutoScaling feature. Using the steps here, you can enable AutoScaling on your existing tables. Alternately, you can also use the on-demand option. This option allows you to pay-per-request for read and write requests so that you only pay for what you use, making it easy to balance costs and performance.